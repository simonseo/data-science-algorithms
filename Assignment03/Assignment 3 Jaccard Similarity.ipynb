{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext Cython\n",
    "import numpy as np\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import codecs\n",
    "from datetime import datetime\n",
    "from hashlib import sha512\n",
    "import itertools\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#chop.py: simply chops the first however many lines\n",
    "import codecs\n",
    "\n",
    "OUTPUT_LINES = 1000\n",
    "\n",
    "with codecs.open(\"data_v1.txt\", \"r\", \"utf-8\") as infile:\n",
    "    with codecs.open(\"data_out_{}.txt\".format(OUTPUT_LINES), \"w\", \"utf-8\") as outfile:\n",
    "        for i, line in enumerate(infile):\n",
    "            if i > OUTPUT_LINES:\n",
    "                break\n",
    "            outfile.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# randomsample.py\n",
    "# Randomly samples however many lines needed \n",
    "import codecs\n",
    "import random\n",
    "\n",
    "TOTAL_LINES = 10**6 + 2\n",
    "OUTPUT_LINES = 100000\n",
    "p = OUTPUT_LINES/TOTAL_LINES\n",
    "\n",
    "print(\"getting random sample of size {}\".format(OUTPUT_LINES))\n",
    "with codecs.open(\"data_v1.txt\", \"r\", \"utf-8\") as infile:\n",
    "\twith codecs.open(\"data_random_{}.txt\".format(OUTPUT_LINES), \"w\", \"utf-8\") as outfile:\n",
    "\t\toutput_count = 0\n",
    "\t\tfor i, line in enumerate(infile):\n",
    "\t\t\tif output_count < OUTPUT_LINES and random.random() < p:\n",
    "\t\t\t\toutfile.write(line)\n",
    "\t\t\t\toutput_count += 1\n",
    "\t\t\tif output_count >= OUTPUT_LINES:\n",
    "\t\t\t\tbreak\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n",
      "[(1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (2, 0), (2, 0), (2, 0), (3, 0), (3, 0), (3, 0), (4, 0), (5, 0), (5, 0), (6, 0), (7, 0), (7, 0), (8, 0), (10, 0), (11, 0), (12, 0), (12, 1), (14, 0), (14, 1), (15, 0), (15, 1), (17, 0), (17, 1), (19, 0), (19, 1), (22, 0), (22, 1), (25, 0), (25, 1), (28, 0), (28, 1), (31, 0), (31, 1), (35, 0), (35, 1), (39, 0), (39, 1), (44, 0), (44, 1), (50, 0), (50, 1), (56, 0), (56, 1), (63, 0), (63, 1), (70, 0), (70, 1), (79, 0), (79, 1), (89, 0), (89, 1), (100, 0), (100, 1), (112, 0), (112, 1), (125, 0), (125, 1), (125, 2), (141, 0), (141, 1), (141, 2), (158, 0), (158, 1), (158, 2), (177, 0), (177, 1), (177, 2), (199, 0), (199, 1), (199, 2), (223, 0), (223, 1), (223, 2), (251, 0), (251, 1), (251, 2), (281, 0), (281, 1), (281, 2)]\n"
     ]
    }
   ],
   "source": [
    "# findbr.py\n",
    "# Finds (b,r) parameters required for documents of \n",
    "# JS similarity s to be in candidate groups with probability p\n",
    "\n",
    "p = 0.98\n",
    "q = 1 - p\n",
    "s = 0.75\n",
    "rrange = range(2, 20)\n",
    "brange = range(0, 250, 5)\n",
    "\n",
    "res = []\n",
    "\n",
    "for b in brange:\n",
    "    b = 10**(-b/100)\n",
    "    for r in rrange:\n",
    "        if (1 - s**r < q**b):\n",
    "            res.append((int(1/b),r))\n",
    "l = len(res)\n",
    "print(l)\n",
    "if l < 250:\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# findthreshold.py\n",
    "# for given (b,r) parameters, finds at which point s in [0,1] the slope is maximum.\n",
    "# also finds probability of document pairs that have JS=S is in candidate pairs\n",
    "\n",
    "srange = range(0,1000)\n",
    "# ordered b first, r second\n",
    "br = [(32,4), (16,8), (32,8), (8,4), (4,4), (8,2)]\n",
    "\n",
    "fx = lambda s,b,r: 1-(1-s**r)**b\n",
    "tx = lambda b,r: (1/b)**(1/r)\n",
    "S = 0.75\n",
    "\n",
    "for (b,r) in br:\n",
    "    max_slope_threshold = (0, -1) # (s, f'(s))\n",
    "    for s in srange:\n",
    "        s = s/1000\n",
    "        fpx = r*b*(1-s**r)**(b-1)*s**(r-1)\n",
    "        if fpx > max_slope_threshold[1]:\n",
    "            # print(max_slope_threshold)\n",
    "            max_slope_threshold = (s, fpx)\n",
    "    print(\"b {} r {} threshold {} p({}) {}\".format(b, r, max_slope_threshold[0], S, fx(S, b, r)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Finding optimal values of r and b for target JS = 0.75\n",
    "# these are ordered r first, b second\n",
    "l = [(4,32),(8,16),(8,32),(4,8),(4,4),(2,8)]\n",
    "\n",
    "fig = plt.figure(num=None, figsize=(12, 8), dpi=80, facecolor='w', edgecolor='k')\n",
    "for i, (r, b) in enumerate(l):\n",
    "    X = np.arange(0, 1, 0.01)\n",
    "    Y = list(map(lambda x: 1-(1-x**r)**b, X))\n",
    "    plt.subplot(2,3,1+i)\n",
    "    plt.plot(X, Y)\n",
    "    plt.title('$f(x) = 1−(1−x^{{{}}})^{{{}}}$'.format(r, b))\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('f(x)')\n",
    "    x = 0.75\n",
    "    X = r\n",
    "    Y = b\n",
    "    print(X*Y*((1-x**X)**(Y-1))*(x**(X-1)))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-shingle word ['second lord that approaches apace', 'lord that approaches apace i', 'that approaches apace i would', 'approaches apace i would gladly', 'apace i would gladly have', 'i would gladly have him', 'would gladly have him see', 'gladly have him see his', 'have him see his parolles', 'him see his parolles what']\n",
      "k-shingle letters ['secon', 'econd', 'condl', 'ondlo', 'ndlor', 'dlord', 'lordt', 'ordth', 'rdtha', 'dthat', 'thata', 'hatap', 'atapp', 'tappr', 'appro', 'pproa', 'proac', 'roach', 'oache', 'aches']\n",
      "JS based on k-word-shingles 0.05602409638554217\n",
      "JS based on k-letter-shingles 0.015184381778741865\n",
      "minhashes of a single document ['01d91dbb', '003827ba', '0008ec51', '00205e36', '00543879', '00c45d7d', '00f2363e', '001c446a', '001b0925', '001952b7', '0034031f', '0184eaec', '0008c343', '00478322', '004d5735', '002c5838']\n",
      "minhashes of a single document ['0010610b', '00050676', '000f377e', '000ec5da', '00543879', '00c45d7d', '0054913d', '0045602f', '001dc182', '002155d1', '005b3d75', '0050a3fc', '001dd29e', '0048c6a3', '003a062e', '008800ee']\n",
      "0:00:00.011813\n"
     ]
    }
   ],
   "source": [
    "%%cython\n",
    "\n",
    "import string\n",
    "from datetime import datetime\n",
    "from hashlib import sha512\n",
    "import itertools\n",
    "\n",
    "def getWords(line):\n",
    "   words = line.strip().lower().split()\n",
    "   return list( map(lambda w: w.strip(string.punctuation), words) )\n",
    "\n",
    "#k-shingle based on words\n",
    "def kShingleWord(k, line, removeFirstWord=True):\n",
    "    words = getWords(line)\n",
    "    idx = words.pop(0)\n",
    "    result = [' '.join([words[i+j] for j in range(k)]) for i in range(len(words)-k)]\n",
    "    return result if removeFirstWord else (idx, result)\n",
    "    \n",
    "#k-shingle based on letters\n",
    "def kShingle(k, line, removeFirstWord=True):\n",
    "    words = getWords(line)\n",
    "    idx = words.pop(0)\n",
    "    line = ''.join(words)\n",
    "    result = [''.join([line[i+j] for j in range(k)]) for i in range(len(line)-k)]\n",
    "    # if removeFirstWord, return list of elements like ['0075c1c5', '005cf4fb',..., '00ccde89']\n",
    "    # if not removeFirstWord, return list of elements like ('6066', ['0075c1c5', '005cf4fb',..., '00ccde89'])\n",
    "    return result if removeFirstWord else (idx, result)\n",
    "    \n",
    "    \n",
    "\n",
    "st = \"6060 SECOND LORD. That approaches apace. I would gladly have him see his PAROLLES. What the dèvil should move me to undertake the recovery cheek of two pile and a half, but his right cheek is worn bare. COUNTESS. To be young again, if we could, I will be a fool in LAFEU. He was excellent indeed, madam; the King very lately spoke Boys. He was my father; and he is thrice a villain that says such father. He that so generally is at all times good must of Half won is match well made; match, and well make it; PAROLLES. It is to be recovered. But that the merit of service is HELENA. 'Till I have no wife, I have nothing in France.' Here is a pur of Fortune's, sir, or of Fortune's cat, but not CLOWN. You must not think I am so simple but I know the devil not seem to understand him, unless some one among us, whom we FIRST LORD. I am heartily sorry that he'll be glad of this. His part o' th' isle. Then does he say he lent me a solemn leave. His lordship will next morning for France. The them whipt; or I would send them to th' Turk to make eunuchs of. PAROLLES. 'Five or six thousand horse' I said-I will say true- 'or But take the High'st to witness. Then, pray you, tell me: But do not speak to me. Lead me to my chamber. Exeunt \"\n",
    "print(\"k-shingle word\", kShingleWord(5, st)[:10])\n",
    "print(\"k-shingle letters\", kShingle(5, st)[:20])\n",
    "\n",
    "# Jaccard similarity from two lists/sets of strings\n",
    "# if only given s1, assume s1 holds both of the two lists and unpack it\n",
    "def jaccardSim(s1, s2=None):\n",
    "    if s2 is None:\n",
    "        s1, s2 = s1\n",
    "    s1 = set(s1)\n",
    "    s2 = set(s2)\n",
    "    return len(s1 & s2) / len(s1 | s2)\n",
    "\n",
    "#st1 is documents 6393 and 7378 combined, st2 is 6393\n",
    "# similarity should be around 0.5 for both word-shingle and letter-shingle\n",
    "# st1 = \"6393 wear the surplice of humility over the black gown of a big heart. away; know it before the report come. If there be breadth enough BERTRAM. Why, if you have a stomach, to't, monsieur. If you think train'd me like a peasant, obscuring and hiding from me all BERTRAM. I'll lend it thee, my dear, but have no power KING. If it were yours by none of all these ways, See at the end of this file: * CONTENT NOTE (added in 2017) * face; if your lordship be in't, as I believe you are, you must COUNTESS. With very much content, my lord; and I wish it happily CHARMIAN. Nay, if an oily palm be not a fruitful prognostication, I LAFEU. I will buy me a son-in-law in a fair, and toll for this. FIRST SOLDIER. Boskos vauvado. I understand thee, and can speak thy PAROLLES. O my good lord, you were the first that found me. in death, which commits some loving act upon her, she hath such a PAROLLES. By the hand of a soldier, I will undertake it. child at fifty, to whom Herod of Jewry may do homage. Find me to sad a passage 'tis!-whose skill was almost as great as his in death, which commits some loving act upon her, she hath such a CLOWN. Faith, sir, 'a has an English name; but his fisnomy is more itself, which could not be her office to say is come, was 7378 whilst I have a tooth in my head. Why, he's able to lead her a against his valour; and my state that way is dangerous, since I PAROLLES. The Duke knows him for no other but a poor officer of to th' Queen? O that I knew this husband, which you say must ANTONY. That which is now a horse, even with a thought Fare you well, my lord; and believe this of me: there can be no beat thee. I think thou wast created for men to breathe ANTONY. Do so, we'll speak to them; and to-night I'll force much of my father in me as you, albeit I confess your coming dare not give. Wherefore, what's the instance? Tongue, I must put the toothpick, which wear not now. Your date is better in your ANTONY. I would they'd fight i' th' fire or i' th' air; PAROLLES. I know not what the success will be, my lord, but the neighbouring languages, therefore we must every one be a man of KING. Know you this ring? This ring was his of late. when old robes are worn out there are members to make new. If ENOBARBUS. Why, sir, give the gods a thankful sacrifice. When it sadness. My brother Jaques he keeps at school, and report speaks PAROLLES. I beseech your honour to hear me one single word. when he number'd thirty; 'a will be here to-morrow, or I am \"\n",
    "# st2 = \"6393 wear the surplice of humility over the black gown of a big heart. away; know it before the report come. If there be breadth enough BERTRAM. Why, if you have a stomach, to't, monsieur. If you think train'd me like a peasant, obscuring and hiding from me all BERTRAM. I'll lend it thee, my dear, but have no power KING. If it were yours by none of all these ways, See at the end of this file: * CONTENT NOTE (added in 2017) * face; if your lordship be in't, as I believe you are, you must COUNTESS. With very much content, my lord; and I wish it happily CHARMIAN. Nay, if an oily palm be not a fruitful prognostication, I LAFEU. I will buy me a son-in-law in a fair, and toll for this. FIRST SOLDIER. Boskos vauvado. I understand thee, and can speak thy PAROLLES. O my good lord, you were the first that found me. in death, which commits some loving act upon her, she hath such a PAROLLES. By the hand of a soldier, I will undertake it. child at fifty, to whom Herod of Jewry may do homage. Find me to sad a passage 'tis!-whose skill was almost as great as his in death, which commits some loving act upon her, she hath such a CLOWN. Faith, sir, 'a has an English name; but his fisnomy is more itself, which could not be her office to say is come, was \"\n",
    "st1 = \"64415 CLEOPATRA. And when good will is show'd, though't come too short, PAROLLES. Yes, so please your Majesty. I did go between them, as I Is to be frighted out of fear, and in that mood CLEOPATRA. As sweet as balm, as soft as air, as gentle- COUNTESS. I think, sir, you can eat none of this homely meat. COUNTESS. 'Tis the best brine a maiden can season her praise in. restrictions whatsoever. You may copy it, give it away or re-use it makes her story true even to the point of her death. Her death in you it best lies; otherwise a seducer flourishes, and a poor SECOND LORD. Bring him forth. [Exeunt SOLDIERS] Has sat i' th' you. Let the justices make you and Fortune friends; I am for wear the surplice of humility over the black gown of a big heart. STEWARD. Madam, I was very late more near her than I think she BERTRAM. No matter; his heels have deserv'd it, in usurping his PAROLLES. My life, sir, in any case! Not that I am afraid to die, up where it wanted, rather than lack it where there is such The remembrance of her father never approaches her heart but the SECOND LORD. I with a troop of Florentines will suddenly surprise him. But to answer you as you would be understood: he weeps like SOOTHSAYER. I see it in my motion, have it not in my tongue; but \"\n",
    "st2 = \"182027 CLEOPATRA. And when good will is show'd, though't come too short, BERTRAM. Nay, by your leave, hold your hands; though I know his PAROLLES. I do not know if it be it or no. with the divine forfeit of his soul upon oath, never trust my ENOBARBUS. [Aside to CLEOPATRA] 'Tis one of those odd tricks which LAFEU. Mine eyes smell onions; I shall weep anon. [To PAROLLES] she had partaken of my flesh, and cost me the dearest groans of a SECOND LORD. I must go look my twigs; he shall be caught. The third o' th' world is yours, which with a snaffle SECOND LORD. The stronger part of it by her own letters, which HELENA. O, my good lord, when I was like this maid, CLEOPATRA. For the most part, too, they are foolish that are so. of the best that is. In a retreat he outruns any lackey: marry, BERTRAM. I know th' art valiant; and, to the of thy soldiership, trial; which if-Lord have mercy on thee for a hen! So, my good enough to go home. What shall I say I have done? It must be a DUKE. So that, from point to point, now have you hear LAFEU. You beg more than word then. Cox my passion! give me your and I begin to love, as an old man loves money, with no stomach. trial; which if-Lord have mercy on thee for a hen! So, my good \"\n",
    "s1 = kShingle(5, st1)\n",
    "s2 = kShingle(5, st2)\n",
    "print(\"JS based on k-word-shingles\", jaccardSim(s1, s2))\n",
    "s1 = kShingleWord(5, st1)\n",
    "s2 = kShingleWord(5, st2)\n",
    "print(\"JS based on k-letter-shingles\", jaccardSim(s1, s2))\n",
    "\n",
    "\n",
    "# shingles should be given as list of strings\n",
    "# this hashes all shingles (8 hash functions) and for each hash function find minimum value hashes.\n",
    "# the hash might not be a number but okay if hash is consistent and there is a clear ordering (alphabetical here)\n",
    "def minhash(shingles):\n",
    "    h = 16 # no. of hashes we want\n",
    "    l = 8 # length of each hash\n",
    "    hashes = ['z'*l] * h # minhashes are initialized to 'zzzzzzzz'\n",
    "    m = sha512()\n",
    "    for shingle in shingles:\n",
    "        m.update(shingle.encode('utf-8'))\n",
    "        newhash = m.hexdigest()\n",
    "        newhashes = [newhash[i:i+l] for i in range(0,l*h,l)] #divide 128 characters into 16 hashes of length 8\n",
    "        hashes = [min(hashes[i], newhashes[i]) for i in range(h)]\n",
    "    return hashes\n",
    "\n",
    "# st2 = \"6393 wear the surplice of humility over the black gown of a big heart. away; know it before the report come. If there be breadth enough BERTRAM. Why, if you have a stomach, to't, monsieur. If you think train'd me like a peasant, obscuring and hiding from me all BERTRAM. I'll lend it thee, my dear, but have no power KING. If it were yours by none of all these ways, See at the end of this file: * CONTENT NOTE (added in 2017) * face; if your lordship be in't, as I believe you are, you must COUNTESS. With very much content, my lord; and I wish it happily CHARMIAN. Nay, if an oily palm be not a fruitful prognostication, I LAFEU. I will buy me a son-in-law in a fair, and toll for this. FIRST SOLDIER. Boskos vauvado. I understand thee, and can speak thy PAROLLES. O my good lord, you were the first that found me. in death, which commits some loving act upon her, she hath such a PAROLLES. By the hand of a soldier, I will undertake it. child at fifty, to whom Herod of Jewry may do homage. Find me to sad a passage 'tis!-whose skill was almost as great as his in death, which commits some loving act upon her, she hath such a CLOWN. Faith, sir, 'a has an English name; but his fisnomy is more itself, which could not be her office to say is come, was \"\n",
    "\n",
    "startingTime = datetime.now()\n",
    "print(\"minhashes of a single document\", minhash(kShingle(5, st2)))\n",
    "print(\"minhashes of a single document\", minhash(kShingle(5, st1)))\n",
    "print(datetime.now()-startingTime)\n",
    "\n",
    "def C(lst, r):\n",
    "    #returns all \"choose r\" combinations as a set\n",
    "    return set(map(lambda x: tuple(sorted(x)), itertools.combinations(lst, r)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot histogram of distribution of JS\n",
    "# usually between 0.0 and 0.2 (99.99%)\n",
    "OUTPUT_LINES = 1000\n",
    "k = 5\n",
    "\n",
    "with codecs.open(\"data_random_{}.txt\".format(OUTPUT_LINES), \"r\", \"utf-8\") as infile:\n",
    "    lst = map(lambda line: kShingleWord(k, line), infile.read().splitlines()) # samples\n",
    "\n",
    "startTime = datetime.now()\n",
    "print(startTime)\n",
    "pairs = list(itertools.combinations(lst, 2)) # all document combinations\n",
    "jaccard_similarities = list(map(jaccardSim, pairs))\n",
    "\n",
    "plt.subplot()\n",
    "plt.title(\"Jaccard Similarities for #documents={}\".format(OUTPUT_LINES))\n",
    "plt.hist(jaccard_similarities,'auto')\n",
    "plt.show()\n",
    "print(datetime.now() - startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# What are the lowest and highest values of JS in the random file?\n",
    "js = sorted(jaccard_similarities)\n",
    "js[0], js[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SHA-512 api example\n",
    "m = sha512()\n",
    "m.update(\"hello world\".encode('utf-8'))\n",
    "print(m.hexdigest(), len(m.hexdigest()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How long does it take to find shingles? Less than 10 seconds for 10^6 documents\n",
    "OUTPUT_LINES = 100\n",
    "k = 5\n",
    "\n",
    "startingTime = datetime.now()\n",
    "with codecs.open(\"data_random_{}.txt\".format(OUTPUT_LINES), \"r\", \"utf-8\") as infile:\n",
    "    lst = map(lambda line: kShingle(5, line), infile.read().splitlines()) # samples\n",
    "\n",
    "print(datetime.now()-startingTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Caculate minhashes and save in file\n",
    "# takes about 5.6 ms for running minhash with 16 hashes (all derived from 1 SHA-512 function call) on each document.\n",
    "# expected to take about 1.5 hrs for 10^6 documents\n",
    "\n",
    "k = 5\n",
    "\n",
    "startingTime = datetime.now()\n",
    "print(\"Started at {}\".format(startingTime))\n",
    "\n",
    "with codecs.open(\"data_v1.txt\", \"r\", \"utf-8\") as infile:\n",
    "    lst = map(lambda line: kShingle(k, line, False), infile.read().splitlines()) # samples\n",
    "\n",
    "print(\"Finished shingling data at {}\".format(datetime.now()))\n",
    "\n",
    "with codecs.open(\"minhash_data_v1.txt\", \"w\", \"utf-8\") as outfile:\n",
    "    for (idx, shingles) in lst:\n",
    "        outfile.write(\"{} {}\\n\".format(idx, ' '.join(minhash(shingles))))\n",
    "\n",
    "print(\"Finished minhashing data at {}\".format(datetime.now()-startingTime))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-02-18 02:50:32.786674\n",
      "[{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]\n",
      "length of buckets 16\n",
      "0:00:36.517971\n",
      "[('0052f3a0', [1]), ('0070a6be', [2]), ('001f135a', [3]), ('0013811e', [4]), ('000c0342', [5]), ('00700253', [6]), ('0016c791', [7]), ('01312c26', [8]), ('00926889', [9]), ('00051d28', [10]), ('00230c45', [11]), ('01d331f2', [12]), ('00e47b0e', [13]), ('0010c66f', [14]), ('008650f4', [15]), ('000f629a', [16]), ('00703ae1', [17]), ('006351b0', [18]), ('002fe2e1', [19, 146535]), ('003922a8', [20]), ('0031c1fc', [21]), ('0001c729', [22]), ('005c00f7', [23]), ('0022bae1', [24]), ('0036299c', [25]), ('002a5e2f', [26]), ('0006ea45', [27]), ('005a02f6', [28]), ('00317848', [29]), ('001a71ea', [30, 768630, 782122])]\n"
     ]
    }
   ],
   "source": [
    "# Put documents into buckets\n",
    "# create 16 dictionaries, one for each hash.\n",
    "# for each hashed document, put the index of the document into the 16 dictionaries with the hash as the key. like so:\n",
    "\n",
    "# h1dict = {ecba2d : [1]}\n",
    "# h2dict = {dfqfe3 : [1]}\n",
    "# etc.\n",
    "\n",
    "startingTime = datetime.now()\n",
    "print(startingTime)\n",
    "with codecs.open(\"minhash_data_v1.txt\", \"r\") as infile:\n",
    "    lst = map(getWords, infile.read().splitlines())\n",
    "    \n",
    "\n",
    "h = 16 # number of hash functions\n",
    "buckets = [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}]\n",
    "print(buckets)\n",
    "for (j, words) in enumerate(lst):\n",
    "    idx = int(words[0]) #idx of doc\n",
    "    hashes = words[1:] #16 hashes\n",
    "    for (i, hashVal) in enumerate(hashes): # put each hash into their respective buckets\n",
    "#         bucket = buckets[(i+j)%h].get(hashVal, [])\n",
    "        bucket = buckets[i].get(hashVal, [])\n",
    "        bucket.append(idx)\n",
    "        buckets[i][hashVal] = bucket\n",
    "#         if j < 5:\n",
    "#             print('i', i, \" idx\", idx, \" bucket\", bucket, \" buckets[i]\", buckets[i], \" hashVal\", hashVal)\n",
    "print(\"length of buckets\",len(buckets))\n",
    "print(datetime.now() - startingTime)\n",
    "print(list(buckets[1].items())[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# [len(buckets[i]) for i in range(16)]\n",
    "# print(list(buckets[0].values())[:1000])\n",
    "print(list(buckets[1].values())[:1000])\n",
    "print(len(buckets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-02-18 03:19:04.613484\n",
      "0 2\n",
      "Finished row 11741895 0\n",
      "Finished row 12187899 0\n",
      "length of candidate weekends 83832\n",
      "2 4\n",
      "Finished row 13699087 83832\n",
      "Finished row 130388013 83832\n",
      "length of candidate weekends 1071232\n",
      "4 6\n",
      "Finished row 9966891 987408\n",
      "Finished row 10250667 987408\n",
      "length of candidate weekends 1205779\n",
      "6 8\n",
      "Finished row 10292661 134558\n",
      "Finished row 14111571 134558\n",
      "length of candidate weekends 1359942\n",
      "8 10\n",
      "Finished row 9471510 154174\n",
      "Finished row 14132027 154174\n",
      "length of candidate weekends 1562609\n",
      "10 12\n",
      "Finished row 11909920 202677\n",
      "Finished row 42645344 202677\n",
      "length of candidate weekends 1658155\n",
      "12 14\n",
      "Finished row 8714414 95714\n",
      "Finished row 12851207 95714\n",
      "length of candidate weekends 1851122\n",
      "14 16\n",
      "Finished row 12599113 193027\n",
      "Finished row 15227033 193027\n",
      "length of candidate weekends 2172651\n",
      "0:07:56.926840\n"
     ]
    }
   ],
   "source": [
    "# divide into b=8 bands, r=2 rows\n",
    "# for each band, find all combinations of documents that are put in same buckets in all rows\n",
    "\n",
    "b=8\n",
    "r=2\n",
    "candidates = set([])\n",
    "keylessBuckets = list(map(lambda row: set(map(tuple, row.values())), buckets)) #list of set of tuples\n",
    "\n",
    "startingTime = datetime.now()\n",
    "print(startingTime)\n",
    "\n",
    "for i in range(0,b*r,r):\n",
    "    print(i, i+r)\n",
    "    band = keylessBuckets[i:i+r]\n",
    "\n",
    "    listOfRowCandidates = []\n",
    "    for row in band: # row is [['1'], ['1', '18566'], ['1'], ['1'], ['1']..] set of tuples\n",
    "        rowCandidates = set([]) # all pairs from a row\n",
    "        for bucket in row: # bucket is ['2', '126908', '203926', '278946', '746802'] tuples\n",
    "            rowCandidates |= C(bucket, 2)\n",
    "        listOfRowCandidates.append(rowCandidates)\n",
    "        print(\"Finished row\", len(rowCandidates))\n",
    "    intersection = listOfRowCandidates[0] # intersections of rows in same band. pair becomes candidate if exists in all rows of a band\n",
    "    for rowCandidates in listOfRowCandidates:\n",
    "        intersection &= rowCandidates\n",
    "    candidates |= intersection\n",
    "    print(\"length of intersections within band\", len(intersection))\n",
    "    print(\"length of candidate weekends\", len(candidates))\n",
    "\n",
    "print(datetime.now()-startingTime)\n",
    "# print(len(candidates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(168815,), (788986,), (896917,), (620731,), (696150,), (413770,), (521957,), (93552,), (801190,), (616807,), (272987,), (409846,), (177079,), (937181,), (596227,), (704414,), (317959,), (422034,), (497453,), (69048,), (172115,), (837358,), (592303,), (699450,), (418110,), (493513,), (80484,), (217343,), (945445,), (599627,)]\n",
      "[(397455, 781325), (117566, 457487), (660663, 715089), (903199, 909040), (840314, 987113), (9243, 622219), (245873, 965452), (80710, 572973), (218239, 468308), (851610, 984999), (20733, 85284), (495367, 819101), (895737, 958614), (54459, 940475), (623219, 868093), (499379, 857041), (287393, 709742), (503603, 936002), (311938, 626678), (523253, 858372), (17334, 234216), (85284, 928194), (130985, 637240), (918249, 954291), (37952, 865783), (378371, 653166), (849044, 896442), (388812, 485730), (64415, 182027), (300381, 967165)]\n",
      "2172651\n",
      "[(267533, 901208), (56063, 763433), (20236, 478553), (491655, 786183), (397636, 679312), (457859, 923496), (634234, 635144), (706471, 969092), (158334, 683141), (518151, 780732), (392419, 608561), (209716, 577348), (911449, 941481), (749415, 853576), (215810, 947866), (590757, 808037), (243478, 380955), (171110, 199772), (10731, 23516), (644387, 778891), (222339, 940990), (141662, 895452), (413853, 456610), (784502, 879528), (142317, 495401), (642470, 716177), (949888, 959656), (791308, 809718), (44567, 584871), (237783, 955984)]\n"
     ]
    }
   ],
   "source": [
    "print(list(keylessBuckets[0])[:30])\n",
    "print(list(candidates)[:30])\n",
    "print(len(candidates))\n",
    "print(list(rowCandidates)[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30865\n"
     ]
    }
   ],
   "source": [
    "docsInCandidates = set([])\n",
    "for (i,j) in candidates:\n",
    "    docsInCandidates |= set([i,j])\n",
    "print(len(docsInCandidates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-02-18 04:24:38.030107\n",
      "done processing... 0:00:37.458920\n",
      "1 0.9487179487179487 (197904, 704395) (['offic', 'ffice', 'ficeo', 'iceof', 'ceofg', 'eofgo', 'ofgod', 'fgoda', 'godan', 'odand', 'dandt', 'andth', 'ndthe', 'dthed', 'thede', 'hedev', 'edevi', 'devil', 'evilo', 'vilon', 'ilone', 'loneb', 'onebr', 'nebri', 'ebrin', 'bring', 'rings', 'ingst', 'ngsth', 'gsthe', 'sthei', 'thein', 'heing', 'eingr', 'ingra', 'ngrac', 'grace', 'racea', 'acean', 'ceand', 'eandt', 'andth', 'ndthe', 'dthem', 'themo', 'hemos', 'emost', 'mostc', 'ostco', 'stcou', 'tcour', 'court', 'ourte', 'urteo', 'rteou', 'teous', 'eousf', 'ousfe', 'usfea', 'sfeat', 'feath', 'eathe', 'ather', 'thers', 'hersw', 'erswh', 'rswhi', 'swhic', 'which', 'hichb', 'ichbo', 'chbow', 'hbowt', 'bowth', 'owthe', 'wtheh', 'thehe', 'hehea', 'ehead', 'heada', 'eadan', 'adand', 'dandn', 'andno', 'ndnod', 'dnoda', 'nodat', 'odate', 'datev', 'ateve', 'tever', 'every', 'verym', 'eryma', 'ryman', 'ymanc', 'manca', 'ancan', 'ncann', 'canno', 'annot', 'nnoty', 'notye', 'otyet', 'tyetf', 'yetfi', 'etfin', 'tfind', 'findi', 'indin', 'ndinm', 'dinmy', 'inmyh', 'nmyhe', 'myhea', 'yhear', 'heart', 'eartt', 'artto', 'rttor', 'ttore', 'torep', 'orepe', 'repen', 'epent', 'penth', 'enthe', 'nther', 'there', 'hereh', 'erehe', 'rehec', 'eheco', 'hecom', 'ecome', 'comes', 'omesi', 'mesip', 'esipr', 'sipra', 'ipray', 'prayy', 'rayyo', 'ayyou', 'yyoue', 'youex', 'ouext', 'uexte', 'exten', 'xtend', 'tendh', 'endhi', 'ndhis', 'dhism', 'hismi', 'ismig', 'smigh', 'might', 'ighto', 'ghton', 'htonl', 'tonly', 'onlyw', 'nlywh', 'lywhe', 'ywher', 'where', 'hereq', 'erequ', 'requa', 'equal', 'quali', 'ualit', 'aliti', 'litie', 'ities', 'tiesw', 'ieswe', 'eswer', 'swere', 'werel', 'erele', 'relev', 'eleve', 'level', 'eveld', 'veldi', 'eldia', 'ldian', 'diana', 'ianan', 'anano', 'nanoq', 'anoqu', 'noque', 'oquee', 'queen', 'ueenm', 'eenme', 'enmen', 'nmena', 'menas', 'enasi', 'nasit', 'asith', 'sithi', 'ithin', 'think', 'hinkt', 'inkth', 'nkthe', 'kthep', 'thepo', 'hepol', 'epoli', 'polic', 'olicy', 'licyo', 'icyof', 'cyoft', 'yofth', 'oftha', 'fthat', 'thatp', 'hatpu', 'atpur', 'tpurp', 'purpo', 'urpos', 'rpose', 'posem', 'osema', 'semad', 'emade', 'madem', 'ademo', 'demor', 'emore', 'morei', 'orein', 'reint', 'einth', 'inthe', 'nthem', 'thema', 'hemar', 'emarr', 'marri', 'arria', 'rriag', 'riage', 'iagef', 'agefi', 'gefir', 'efirs', 'first', 'irsts', 'rstso', 'stsol', 'tsold', 'soldi', 'oldie', 'ldier', 'dieri', 'ierif', 'erify', 'rifyo', 'ifyou', 'fyouc', 'youco', 'oucou', 'ucoul', 'could', 'ouldf', 'uldfi', 'ldfin', 'dfind', 'findo', 'indou', 'ndout', 'douta', 'outac', 'utaco', 'tacou', 'acoun', 'count', 'ountr', 'untry', 'ntryw', 'trywh', 'rywhe', 'ywher', 'where', 'hereb', 'erebu', 'rebut', 'ebutw', 'butwo', 'utwom', 'twome', 'women', 'omenw', 'menwe', 'enwer', 'nwere', 'weret', 'ereth', 'retho', 'ethou', 'thoug', 'hough', 'oughy', 'ughyo', 'ghyou', 'hyouu', 'youun', 'ouund', 'uunde', 'under', 'nders', 'derst', 'ersta', 'rstan', 'stand', 'tandi', 'andit', 'nditn', 'ditno', 'itnot', 'tnoty', 'notyo', 'otyou', 'tyour', 'yours', 'ourse', 'ursel', 'rselv', 'selve', 'elves', 'lvesn', 'vesno', 'esnom', 'snoma', 'nomat', 'omatt', 'matte', 'atter', 'tterf', 'terfo', 'erfor', 'rforw', 'forwe', 'orwem', 'rwemu', 'wemus', 'emust', 'mustf', 'ustfi', 'stfir', 'tfirs', 'first', 'irsts', 'rstso', 'stsol', 'tsold', 'soldi', 'oldie', 'ldier', 'dierf', 'ierfo', 'erfol', 'rfoll', 'follo', 'ollow', 'llowt', 'lowth', 'owthe', 'wthen', 'theno', 'henoi', 'enois', 'noise', 'oises', 'iseso', 'sesof', 'esofa', 'sofar', 'ofara', 'faras', 'arasw', 'raswe', 'asweh', 'sweha', 'wehav', 'ehave', 'haveq', 'avequ', 'vequa', 'equar', 'quart', 'uarte', 'arter', 'rters', 'terse', 'ersec', 'rseco', 'secon', 'econd', 'condl', 'ondlo', 'ndlor', 'dlord', 'lordh', 'ordhe', 'rdheh', 'dheha', 'hehas', 'ehasm', 'hasmu', 'asmuc', 'smuch', 'muchw', 'uchwo', 'chwor', 'hwort', 'worth', 'orthy', 'rthyb', 'thybl', 'hybla', 'yblam', 'blame', 'lamel', 'amela', 'melai', 'elaid', 'laidu', 'aidup', 'idupo', 'dupon', 'uponh', 'ponhi', 'onhim', 'nhimf', 'himfo', 'imfor', 'mfors', 'forsh', 'orsha', 'rshak', 'shaki', 'hakin', 'aking', 'kingo', 'ingof', 'ngoff', 'goffc', 'offco', 'ffcou', 'fcoun', 'count', 'ounte', 'untes', 'ntess', 'tessg', 'essge', 'ssget', 'sgety', 'getyo', 'etyou', 'tyoug', 'yougo', 'ougon', 'ugone', 'gones', 'onesi', 'nesir', 'esiri', \"siri'\", \"iri'l\", \"ri'll\", \"i'llt\", \"'llta\", 'lltal', 'ltalk', 'talkw', 'alkwi', 'lkwit', 'kwith', 'withy', 'ithyo', 'thyou', 'hyoum', 'youmo', 'oumor', 'umore', 'morea', 'orean', 'reano', 'eanon', 'anonl', 'nonla', 'onlaf', 'nlafe', 'lafeu', 'afeui', 'feuid', 'euidi', 'uidid', 'ididt', 'didth', 'idthi', 'dthin', 'think', 'hinkt', 'inkth', 'nkthe', 'kthee', 'theef', 'heefo', 'eefor', 'efort', 'fortw', 'ortwo', 'rtwoo', 'twoor', 'woord', 'oordi', 'ordin', 'rdina', 'dinar', 'inari', 'narie', 'aries', 'riest', 'iesto', 'estob', 'stobe', 'tobea', 'obeap', 'beapr', 'eapre', 'apret', 'prett', 'retty', 'ettyw', 'ttywi', 'tywis', 'ywise', 'wiset', 'iseth', 'sethr', 'ethre', 'threa', 'hreat', 'reate', 'eaten', 'atens', 'tenst', 'ensth', 'nsthe', 'sthem', 'themi', 'hemih', 'emiho', 'mihop', 'ihope', 'hopei', 'opein', 'peine', 'einee', 'ineed', 'needn', 'eedno', 'ednot', 'dnott', 'notto', 'ottoa', 'ttoad', 'toadv', 'oadvi', 'advis', 'dvise', 'visey', 'iseyo', 'seyou', 'eyouf', 'youfu', 'oufur', 'ufurt', 'furth', 'urthe', 'rther', 'therb', 'herbu', 'erbut', 'rbuti', 'butic', 'utich', 'tiche', 'ichee', 'cheek', 'heeko', 'eekof', 'ekoft', 'koftw', 'oftwo', 'ftwop', 'twopi', 'wopil', 'opile', 'pilea', 'ilean', 'leand', 'eanda', 'andah', 'ndaha', 'dahal', 'ahalf', 'halfb', 'alfbu', 'lfbut', 'fbuth', 'buthi', 'uthis', 'thisr', 'hisri', 'isrig', 'srigh', 'right', 'ightc', 'ghtch', 'htche', 'tchee', 'cheek', 'heeki', 'eekis', 'ekisw', 'kiswo', 'iswor', 'sworn', 'wornb', 'ornba', 'rnbar', 'nbare', 'barel', 'arela', 'relaf', 'elafe', 'lafeu', 'afeun', 'feuno', 'eunon', 'unono', 'nonon', 'onono', 'nonos', 'onoso', 'noson', 'osonw', 'sonwa', 'onwas', 'nwasm', 'wasmi', 'asmis', 'smisl', 'misle', 'isled', 'sledw', 'ledwi', 'edwit', 'dwith', 'witha', 'ithas', 'thasn', 'hasni', 'asnip', 'snipt', 'nipt-', 'ipt-t', 'pt-ta', 't-taf', '-taff', 'taffe', 'affet', 'ffeta', 'fetaf', 'etafe', 'tafel', 'afell', 'fello', 'ellow', 'llowy', 'lowyo', 'owyou', 'wyouw', 'youwr', 'ouwri', 'uwrit', 'writt', 'ritto', 'ittod', 'ttodi', 'todia', 'odian', 'diana', 'ianai', 'anain', 'nainb', 'ainbe', 'inbeh', 'nbeha', 'behal', 'ehalf', 'halfo', 'alfof', 'lfoft', 'fofth', 'ofthe', 'fthec', 'theco', 'hecou', 'ecoun', 'count', 'ountr', 'untro', 'ntrou', 'trous', 'rousi', 'ousil', 'usill', 'sillo', 'illon', 'llona', 'lonan', 'onani', 'naniw', 'aniwe', 'niwer', 'iwere', 'weren', 'ereno', 'renot', 'enoti', 'notin', 'otinc', 'tincr', 'incre', 'ncrea', 'creas', 'rease', 'easea', 'asean', 'seand', 'eandt', 'andth', 'ndthe', 'dther', 'there', 'herew', 'erewa', 'rewas', 'ewasn', 'wasne', 'asnev', 'sneve', 'never', 'everv', 'vervi', 'ervir', 'rvirg', 'virgi', 'irgin', 'rging', 'gingo', 'ingot', 'ngott', 'gotti', 'ottil', 'ttill', 'tillv', 'illvi', 'llvir', 'lvirg', 'virgi', 'irgin', 'rgini', 'ginit', 'inity', 'nityw', 'itywa', 'tywas', 'ywasf', 'wasfi', 'asfir', 'sfirs', 'first', 'irstf', 'rstfl', 'stflo', 'tflow', \"flow'\", \"low'r\", \"ow'ry\", \"w'ryw\", \"'rywa\", 'ryway', 'ywayt', 'wayth', 'aytha', 'ythat', 'thatl', 'hatle', 'atlea', 'tlead', 'leads', 'eadst', 'adsto', 'dstot', 'stoth', 'tothe', 'otheb', 'thebr', 'hebro', 'ebroa', 'broad', 'roadg', 'oadga', 'adgat', 'dgate', 'gatea', 'atean', 'teand', 'eandt', 'andth', 'ndthe', 'dtheg', 'thegr', 'hegre', 'egrea', 'great', 'reatf', 'eatfi', 'atfir', 'tfire', 'firef', 'irefi', 'refir', 'efirs', 'first', 'irsts', 'rstso', 'stsol', 'tsold', 'soldi', 'oldie', 'ldier', 'dierh', 'ierhe', 'erher', 'rhere', 'heret', 'ereti', 'retis', 'etish', 'tishe', 'isher', 'shere', \"here'\", \"ere's\", \"re'sa\", \"e'sap\", \"'sapa\", 'sapap', 'apape', 'paper', 'apers', 'persh', 'ersha', 'rshal', 'shall', 'halli', 'allir', 'llire', 'lirea', 'iread', 'readi', 'eadit', 'aditt', 'ditto', 'ittoy', 'ttoyo', 'toyou', 'oyouh', 'youho', 'ouhou', 'uhous', 'house', 'ouseh', 'usehe', 'seher', 'eherp', 'herpr', 'erpre', 'rpret', 'prete', 'reten', 'etenc', 'tence', 'encei', 'nceis', 'ceisa', 'eisap', 'isapi', 'sapil', 'apilg', 'pilgr', 'ilgri', 'lgrim', 'grima', 'rimag', 'image', 'maget', 'ageto', 'getos', 'etosa', 'tosai', 'osain', 'saint', 'aintj', 'intja', 'ntjaq', 'tjaqu', 'jaque', 'aques', 'quesl', 'uesle', 'esleg', 'slegr', 'legra', 'egran', 'grand', 'rands', 'andse', 'ndsec', 'dseco', 'secon', 'econd', 'condl', 'ondlo', 'ndlor', 'dlord', 'lordi', 'ordim', 'rdimu', 'dimus', 'imust', 'mustg', 'ustgo', 'stgol', 'tgolo', 'goloo', 'olook', 'lookm', 'ookmy', 'okmyt', 'kmytw', 'mytwi', 'ytwig', 'twigs', 'wigsh', 'igshe', 'gshes', 'shesh', 'hesha', 'eshal', 'shall', 'hallb', 'allbe', 'llbec', 'lbeca', 'becau', 'ecaug', 'caugh'], ['offic', 'ffice', 'ficeo', 'iceof', 'ceofg', 'eofgo', 'ofgod', 'fgoda', 'godan', 'odand', 'dandt', 'andth', 'ndthe', 'dthed', 'thede', 'hedev', 'edevi', 'devil', 'evilo', 'vilon', 'ilone', 'loneb', 'onebr', 'nebri', 'ebrin', 'bring', 'rings', 'ingst', 'ngsth', 'gsthe', 'sthei', 'thein', 'heing', 'eingr', 'ingra', 'ngrac', 'grace', 'racea', 'acean', 'ceand', 'eandt', 'andth', 'ndthe', 'dthem', 'themo', 'hemos', 'emost', 'mostc', 'ostco', 'stcou', 'tcour', 'court', 'ourte', 'urteo', 'rteou', 'teous', 'eousf', 'ousfe', 'usfea', 'sfeat', 'feath', 'eathe', 'ather', 'thers', 'hersw', 'erswh', 'rswhi', 'swhic', 'which', 'hichb', 'ichbo', 'chbow', 'hbowt', 'bowth', 'owthe', 'wtheh', 'thehe', 'hehea', 'ehead', 'heada', 'eadan', 'adand', 'dandn', 'andno', 'ndnod', 'dnoda', 'nodat', 'odate', 'datev', 'ateve', 'tever', 'every', 'verym', 'eryma', 'ryman', 'ymanc', 'manca', 'ancan', 'ncann', 'canno', 'annot', 'nnoty', 'notye', 'otyet', 'tyetf', 'yetfi', 'etfin', 'tfind', 'findi', 'indin', 'ndinm', 'dinmy', 'inmyh', 'nmyhe', 'myhea', 'yhear', 'heart', 'eartt', 'artto', 'rttor', 'ttore', 'torep', 'orepe', 'repen', 'epent', 'penth', 'enthe', 'nther', 'there', 'hereh', 'erehe', 'rehec', 'eheco', 'hecom', 'ecome', 'comes', 'omesi', 'mesip', 'esipr', 'sipra', 'ipray', 'prayy', 'rayyo', 'ayyou', 'yyoue', 'youex', 'ouext', 'uexte', 'exten', 'xtend', 'tendh', 'endhi', 'ndhis', 'dhism', 'hismi', 'ismig', 'smigh', 'might', 'ighto', 'ghton', 'htonl', 'tonly', 'onlyw', 'nlywh', 'lywhe', 'ywher', 'where', 'hereq', 'erequ', 'requa', 'equal', 'quali', 'ualit', 'aliti', 'litie', 'ities', 'tiesw', 'ieswe', 'eswer', 'swere', 'werel', 'erele', 'relev', 'eleve', 'level', 'eveld', 'veldi', 'eldia', 'ldian', 'diana', 'ianan', 'anano', 'nanoq', 'anoqu', 'noque', 'oquee', 'queen', 'ueenm', 'eenme', 'enmen', 'nmena', 'menas', 'enasi', 'nasit', 'asith', 'sithi', 'ithin', 'think', 'hinkt', 'inkth', 'nkthe', 'kthep', 'thepo', 'hepol', 'epoli', 'polic', 'olicy', 'licyo', 'icyof', 'cyoft', 'yofth', 'oftha', 'fthat', 'thatp', 'hatpu', 'atpur', 'tpurp', 'purpo', 'urpos', 'rpose', 'posem', 'osema', 'semad', 'emade', 'madem', 'ademo', 'demor', 'emore', 'morei', 'orein', 'reint', 'einth', 'inthe', 'nthem', 'thema', 'hemar', 'emarr', 'marri', 'arria', 'rriag', 'riage', 'iagef', 'agefi', 'gefir', 'efirs', 'first', 'irsts', 'rstso', 'stsol', 'tsold', 'soldi', 'oldie', 'ldier', 'dieri', 'ierif', 'erify', 'rifyo', 'ifyou', 'fyouc', 'youco', 'oucou', 'ucoul', 'could', 'ouldf', 'uldfi', 'ldfin', 'dfind', 'findo', 'indou', 'ndout', 'douta', 'outac', 'utaco', 'tacou', 'acoun', 'count', 'ountr', 'untry', 'ntryw', 'trywh', 'rywhe', 'ywher', 'where', 'hereb', 'erebu', 'rebut', 'ebutw', 'butwo', 'utwom', 'twome', 'women', 'omenw', 'menwe', 'enwer', 'nwere', 'weret', 'ereth', 'retho', 'ethou', 'thoug', 'hough', 'oughy', 'ughyo', 'ghyou', 'hyouu', 'youun', 'ouund', 'uunde', 'under', 'nders', 'derst', 'ersta', 'rstan', 'stand', 'tandi', 'andit', 'nditn', 'ditno', 'itnot', 'tnoty', 'notyo', 'otyou', 'tyour', 'yours', 'ourse', 'ursel', 'rselv', 'selve', 'elves', 'lvesn', 'vesno', 'esnom', 'snoma', 'nomat', 'omatt', 'matte', 'atter', 'tterf', 'terfo', 'erfor', 'rforw', 'forwe', 'orwem', 'rwemu', 'wemus', 'emust', 'mustf', 'ustfi', 'stfir', 'tfirs', 'first', 'irsts', 'rstso', 'stsol', 'tsold', 'soldi', 'oldie', 'ldier', 'dierf', 'ierfo', 'erfol', 'rfoll', 'follo', 'ollow', 'llowt', 'lowth', 'owthe', 'wthen', 'theno', 'henoi', 'enois', 'noise', 'oises', 'iseso', 'sesof', 'esofa', 'sofar', 'ofara', 'faras', 'arasw', 'raswe', 'asweh', 'sweha', 'wehav', 'ehave', 'haveq', 'avequ', 'vequa', 'equar', 'quart', 'uarte', 'arter', 'rters', 'terse', 'ersec', 'rseco', 'secon', 'econd', 'condl', 'ondlo', 'ndlor', 'dlord', 'lordh', 'ordhe', 'rdheh', 'dheha', 'hehas', 'ehasm', 'hasmu', 'asmuc', 'smuch', 'muchw', 'uchwo', 'chwor', 'hwort', 'worth', 'orthy', 'rthyb', 'thybl', 'hybla', 'yblam', 'blame', 'lamel', 'amela', 'melai', 'elaid', 'laidu', 'aidup', 'idupo', 'dupon', 'uponh', 'ponhi', 'onhim', 'nhimf', 'himfo', 'imfor', 'mfors', 'forsh', 'orsha', 'rshak', 'shaki', 'hakin', 'aking', 'kingo', 'ingof', 'ngoff', 'goffc', 'offco', 'ffcou', 'fcoun', 'count', 'ounte', 'untes', 'ntess', 'tessg', 'essge', 'ssget', 'sgety', 'getyo', 'etyou', 'tyoug', 'yougo', 'ougon', 'ugone', 'gones', 'onesi', 'nesir', 'esiri', \"siri'\", \"iri'l\", \"ri'll\", \"i'llt\", \"'llta\", 'lltal', 'ltalk', 'talkw', 'alkwi', 'lkwit', 'kwith', 'withy', 'ithyo', 'thyou', 'hyoum', 'youmo', 'oumor', 'umore', 'morea', 'orean', 'reano', 'eanon', 'anonl', 'nonla', 'onlaf', 'nlafe', 'lafeu', 'afeui', 'feuid', 'euidi', 'uidid', 'ididt', 'didth', 'idthi', 'dthin', 'think', 'hinkt', 'inkth', 'nkthe', 'kthee', 'theef', 'heefo', 'eefor', 'efort', 'fortw', 'ortwo', 'rtwoo', 'twoor', 'woord', 'oordi', 'ordin', 'rdina', 'dinar', 'inari', 'narie', 'aries', 'riest', 'iesto', 'estob', 'stobe', 'tobea', 'obeap', 'beapr', 'eapre', 'apret', 'prett', 'retty', 'ettyw', 'ttywi', 'tywis', 'ywise', 'wiset', 'iseth', 'sethr', 'ethre', 'threa', 'hreat', 'reate', 'eaten', 'atens', 'tenst', 'ensth', 'nsthe', 'sthem', 'themi', 'hemih', 'emiho', 'mihop', 'ihope', 'hopei', 'opein', 'peine', 'einee', 'ineed', 'needn', 'eedno', 'ednot', 'dnott', 'notto', 'ottoa', 'ttoad', 'toadv', 'oadvi', 'advis', 'dvise', 'visey', 'iseyo', 'seyou', 'eyouf', 'youfu', 'oufur', 'ufurt', 'furth', 'urthe', 'rther', 'therb', 'herbu', 'erbut', 'rbuti', 'butic', 'utich', 'tiche', 'ichee', 'cheek', 'heeko', 'eekof', 'ekoft', 'koftw', 'oftwo', 'ftwop', 'twopi', 'wopil', 'opile', 'pilea', 'ilean', 'leand', 'eanda', 'andah', 'ndaha', 'dahal', 'ahalf', 'halfb', 'alfbu', 'lfbut', 'fbuth', 'buthi', 'uthis', 'thisr', 'hisri', 'isrig', 'srigh', 'right', 'ightc', 'ghtch', 'htche', 'tchee', 'cheek', 'heeki', 'eekis', 'ekisw', 'kiswo', 'iswor', 'sworn', 'wornb', 'ornba', 'rnbar', 'nbare', 'barel', 'arela', 'relaf', 'elafe', 'lafeu', 'afeun', 'feuno', 'eunon', 'unono', 'nonon', 'onono', 'nonos', 'onoso', 'noson', 'osonw', 'sonwa', 'onwas', 'nwasm', 'wasmi', 'asmis', 'smisl', 'misle', 'isled', 'sledw', 'ledwi', 'edwit', 'dwith', 'witha', 'ithas', 'thasn', 'hasni', 'asnip', 'snipt', 'nipt-', 'ipt-t', 'pt-ta', 't-taf', '-taff', 'taffe', 'affet', 'ffeta', 'fetaf', 'etafe', 'tafel', 'afell', 'fello', 'ellow', 'llowy', 'lowyo', 'owyou', 'wyouw', 'youwr', 'ouwri', 'uwrit', 'writt', 'ritto', 'ittod', 'ttodi', 'todia', 'odian', 'diana', 'ianai', 'anain', 'nainb', 'ainbe', 'inbeh', 'nbeha', 'behal', 'ehalf', 'halfo', 'alfof', 'lfoft', 'fofth', 'ofthe', 'fthec', 'theco', 'hecou', 'ecoun', 'count', 'ountr', 'untro', 'ntrou', 'trous', 'rousi', 'ousil', 'usill', 'sillo', 'illon', 'llona', 'lonan', 'onani', 'naniw', 'aniwe', 'niwer', 'iwere', 'weren', 'ereno', 'renot', 'enoti', 'notin', 'otinc', 'tincr', 'incre', 'ncrea', 'creas', 'rease', 'easea', 'asean', 'seand', 'eandt', 'andth', 'ndthe', 'dther', 'there', 'herew', 'erewa', 'rewas', 'ewasn', 'wasne', 'asnev', 'sneve', 'never', 'everv', 'vervi', 'ervir', 'rvirg', 'virgi', 'irgin', 'rging', 'gingo', 'ingot', 'ngott', 'gotti', 'ottil', 'ttill', 'tillv', 'illvi', 'llvir', 'lvirg', 'virgi', 'irgin', 'rgini', 'ginit', 'inity', 'nityw', 'itywa', 'tywas', 'ywasf', 'wasfi', 'asfir', 'sfirs', 'first', 'irstf', 'rstfi', 'stfir', 'tfirs', 'first', 'irsts', 'rstso', 'stsol', 'tsold', 'soldi', 'oldie', 'ldier', 'dierh', 'ierhe', 'erher', 'rhere', 'heret', 'ereti', 'retis', 'etish', 'tishe', 'isher', 'shere', \"here'\", \"ere's\", \"re'sa\", \"e'sap\", \"'sapa\", 'sapap', 'apape', 'paper', 'apers', 'persh', 'ersha', 'rshal', 'shall', 'halli', 'allir', 'llire', 'lirea', 'iread', 'readi', 'eadit', 'aditt', 'ditto', 'ittoy', 'ttoyo', 'toyou', 'oyouh', 'youho', 'ouhou', 'uhous', 'house', 'ouseh', 'usehe', 'seher', 'eherp', 'herpr', 'erpre', 'rpret', 'prete', 'reten', 'etenc', 'tence', 'encei', 'nceis', 'ceisa', 'eisap', 'isapi', 'sapil', 'apilg', 'pilgr', 'ilgri', 'lgrim', 'grima', 'rimag', 'image', 'maget', 'ageto', 'getos', 'etosa', 'tosai', 'osain', 'saint', 'aintj', 'intja', 'ntjaq', 'tjaqu', 'jaque', 'aques', 'quesl', 'uesle', 'esleg', 'slegr', 'legra', 'egran', 'grand', 'rands', 'andse', 'ndsec', 'dseco', 'secon', 'econd', 'condl', 'ondlo', 'ndlor', 'dlord', 'lordi', 'ordim', 'rdimu', 'dimus', 'imust', 'mustg', 'ustgo', 'stgol', 'tgolo', 'goloo', 'olook', 'lookm', 'ookmy', 'okmyt', 'kmytw', 'mytwi', 'ytwig', 'twigs', 'wigsh', 'igshe', 'gshes', 'shesh', 'hesha', 'eshal', 'shall', 'hallb', 'allbe', 'llbec', 'lbeca', 'becau', 'ecaug', 'caugh'])\n",
      "2\n",
      "0:06:24.955809\n"
     ]
    }
   ],
   "source": [
    "# for each candidate pair in the list, \n",
    "# calculate the actual Jaccard Similarity and if JS > 0.75, \n",
    "# add to output list\n",
    "k = 5\n",
    "\n",
    "startingTime = datetime.now()\n",
    "print(startingTime)\n",
    "with codecs.open(\"data_v1.txt\", \"r\", \"utf-8\") as infile:\n",
    "    lst = [kShingle(k, line) if int(line.split(' ',1)[0]) in docsInCandidates else [''] for line in infile.read().splitlines() ] # samples\n",
    "\n",
    "print(\"done processing...\", datetime.now()-startingTime)\n",
    "\n",
    "    \n",
    "output = []\n",
    "count = 0\n",
    "logcount = 0\n",
    "for (i,j) in candidates:\n",
    "    js = jaccardSim(lst[i-1], lst[j-1])\n",
    "    if (js > 0.75):\n",
    "        output.append((i,j))\n",
    "        count+=1\n",
    "        if math.log10(count) == logcount:\n",
    "            print(count, js, (i,j), (lst[i-1], lst[j-1]))\n",
    "            logcount += 1\n",
    "print(len(output))\n",
    "\n",
    "print(datetime.now() - startingTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaccardSim(lst[322400-1],lst[370208-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# b=8\n",
    "# r=2\n",
    "# candidates = set([])\n",
    "# startingTime = datetime.now()\n",
    "# print(startingTime)\n",
    "# keylessBuckets = list(map(lambda row: set(map(tuple, row.values())), buckets))\n",
    "\n",
    "# print(\"finished keylessbucketing\", datetime.now()-startingTime)\n",
    "\n",
    "# for i in range(0,b,r):\n",
    "#     band = keylessBuckets[i:i+r]\n",
    "#     intersection = set([]) # intersections of rows in same band. pair becomes candidate if exists in all rows of a band\n",
    "#     for row in band: # row is [['1'], ['1', '18566'], ['1'], ['1'], ['1']..]\n",
    "#         rowCandidates = set([]) # all pairs from a row\n",
    "#         print(\"length of row\", len(row))\n",
    "#         for i, bucket in enumerate(row): # bucket is ['2', '126908', '203926', '278946', '746802']\n",
    "#             rowCandidates |= C(bucket, 2)\n",
    "#             if i%(10**4):\n",
    "#                 print(\"finished 10**4 buckets \",datetime.now()-startingTime)                \n",
    "#         print(\"finished row\", datetime.now()-startingTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lst = ('df','asd','asdf')\n",
    "for i, ls in enumerate(lst):\n",
    "    print(i,ls)\n",
    "print(C(lst,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "10\n",
      "100\n",
      "1000\n",
      "10000\n",
      "100000\n",
      "1000000\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "logcount = 0\n",
    "for i in range(10**20):\n",
    "    count+=1\n",
    "    if math.log10(count) == logcount:\n",
    "        print(count)\n",
    "        logcount += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
